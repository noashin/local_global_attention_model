{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fitting analysis\n",
    "The goal of this notebook is to perform the ability of the different models to fit the data.\n",
    "The main way to do so is to generate data from the fitted models and compare the statistics of the fitted data with the statistics of the real data.\n",
    "\n",
    "The analysis bellow is done only to one fold from the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.FullModel.model import Model as full_model\n",
    "from src.FullModel.epsilon_param import EpsParam as epsilon_object\n",
    "from src.FullModel.xi_param import XiParam as xi_object\n",
    "\n",
    "from src.LocalGlobalAttentionModel.b_param import BParam as b_object\n",
    "from src.LocalGlobalAttentionModel.s0_param import S0Param as s_0_object\n",
    "\n",
    "from src.LocalChoiceModel.model import Model as local_choice_model\n",
    "\n",
    "from src.FixedChoiceModel.model import Model as fixed_choice_model\n",
    "from src.FixedChoiceModel.rho_param import RhoParam as rho_object\n",
    "\n",
    "from src.LocalSaliencyModel.model import Model as local_saliency_model\n",
    "from src.LocalSaliencyModel.xi_param import XiParam as xi_object_local_saliency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tehse are functions that will help us to read and process the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_samples_files(file_name, burnin):\n",
    "    \"\"\"\n",
    "    This function reads the results of an inference for one subject assuming one chain.\n",
    "    :param file_name: path to the file containing the inference results.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_name, 'rb') as f:\n",
    "        # Expected - a list where each item is a numpy array containing the sample for a parametr.\n",
    "        res = pickle.load(f)\n",
    "\n",
    "    samps_0 = np.array(res[0])\n",
    "    if 0 in samps_0:\n",
    "        # Could be that the end of the chains contains 0s. We don't want to return them.\n",
    "        eff_len = np.where(samps_0 == 0)[0][0]\n",
    "    else:\n",
    "        eff_len = samps_0.shape[0]\n",
    "\n",
    "    processed_result = []\n",
    "    # go over each parameter\n",
    "    for i, result in enumerate(res):\n",
    "        tmp_res = np.array(result)[:eff_len]\n",
    "        # if it is a parameter with multiple dimensions - separate the chain of each dimension.\n",
    "        if len(tmp_res.shape) > 1:\n",
    "            s = tmp_res.shape[1]\n",
    "            for j in range(s):\n",
    "                processed_result.append(tmp_res[burnin:, j])\n",
    "        else:\n",
    "            processed_result.append(tmp_res[burnin:])\n",
    "    return np.array(processed_result)\n",
    "\n",
    "\n",
    "def read_folder(folder_path, burnin):\n",
    "    \"\"\"\n",
    "    This function iterates over the results of an experiment.\n",
    "    It expects one output file per subject, where the subject index is the last characters of the file name.\n",
    "    :param folder_path: path to the folder containing the results-\n",
    "    :return: Dictionary with subject index as key and the results of read_samples_files as value.\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if 'sub' not in file_name:\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                sub_ind = int(file_path[-4:-2])\n",
    "            except ValueError:\n",
    "                sub_ind = int(file_path[-3:-2])\n",
    "\n",
    "            tmp_res = read_samples_files(file_path, burnin)\n",
    "            res[sub_ind] = tmp_res\n",
    "    return res\n",
    "\n",
    "def pix_to_degs(fixations):\n",
    "    \"\"\"\n",
    "    The models generate data in pixels and we want to convert it to visual degrees.\n",
    "    \"\"\"\n",
    "    shape = [64, 64]\n",
    "    range_x = [1.035, 32.1]\n",
    "    range_y = [0.82, 25.68]\n",
    "    shape_degs = [range_x[1] - range_x[0], range_y[1] - range_y[0]]\n",
    "    deg_fixs = []\n",
    "    conv = np.array([shape_degs[0] / shape[0], shape_degs[1] / shape[1]])\n",
    "    num_pixs = 128\n",
    "\n",
    "    for fixs_im in fixations:\n",
    "        deg_fixs.append([])\n",
    "        for fixs_sub in fixs_im:\n",
    "            try:\n",
    "                deg_fixs[-1].append((fixs_sub.T * conv + np.array([range_x[0], range_y[0]])).T)\n",
    "            except ValueError:\n",
    "                deg_fixs[-1].append((fixs_sub[:-1, :].T * conv).T)\n",
    "\n",
    "\n",
    "    return deg_fixs\n",
    "\n",
    "def get_kdes_estimates(data, positions):\n",
    "    \"\"\"\n",
    "    This function takes dataset of saccades amplitudes and uses kde\n",
    "    to get the frequency of saccade amplitudes.\n",
    "    \"\"\"\n",
    "    shape = data.shape\n",
    "    res = np.zeros((shape[0], shape[1], positions.shape[0]))\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            kde = gaussian_kde(data[i, j])\n",
    "            res[i, j] = kde(positions)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fixations_path = '../DATA/processed_data/test_fixs_for_cross_validation.p'\n",
    "test_saliencies_path = '../DATA/processed_data/test_sals_for_cross_validation.p'\n",
    "\n",
    "fold = 0\n",
    "\n",
    "with open(test_fixations_path, 'rb') as f:\n",
    "    test_fixations = pickle.load(f)\n",
    "    \n",
    "with open(test_saliencies_path, 'rb') as f:\n",
    "    test_saliencies = pickle.load(f)\n",
    "    \n",
    "test_fixations = test_fixations[fold]\n",
    "test_saliencies = test_saliencies[fold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each subject we create a model with the parameters values, as they were inferred for this subject.\n",
    "Since the inference results in a distribution, we sample multiple configurations for each parameter.\n",
    "We will generate later data from these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin = 5000\n",
    "num_samples = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_results = '../Results/cross_validation/full_model_fold_0'\n",
    "full_model_samples = read_folder(full_model_results, burnin)\n",
    "\n",
    "full_model_objects_dict = {}\n",
    "\n",
    "for sub in full_model_samples.keys():\n",
    "    try:\n",
    "        samples_s_0, samples_b, samples_epsilon_x, samples_epsilon_y, samples_xi_x, samples_xi_y = full_model_samples[sub]\n",
    "    except ValueError:\n",
    "        print(sub)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        full_model_objects_dict[sub] = []\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            chosen_ind = int(np.random.choice(np.linspace(0, len(samples_s_0) - 1,len(samples_s_0))))\n",
    "            s_0 = samples_s_0[chosen_ind]\n",
    "            b = samples_b[chosen_ind]\n",
    "            eps_x = samples_epsilon_x[chosen_ind]\n",
    "            eps_y = samples_epsilon_y[chosen_ind]\n",
    "            xi_x = samples_xi_x[chosen_ind]\n",
    "            xi_y = samples_xi_y[chosen_ind]\n",
    "            \n",
    "            s_0_ob = s_0_object()\n",
    "            s_0_ob.set_value(s_0)\n",
    "\n",
    "            b_ob = b_object()\n",
    "            b_ob.set_value(b)\n",
    "\n",
    "            eps_ob = epsilon_object()\n",
    "            eps_ob.set_value(np.array([eps_x, eps_y]))\n",
    "\n",
    "            xi_ob = xi_object()\n",
    "            xi_ob.set_value(np.array([xi_x, xi_y]))\n",
    "\n",
    "            cov_ratio = 4\n",
    "            full_model_objects_dict[sub].append(full_model(test_saliencies, \n",
    "                                                           s_0_ob, b_ob, eps_ob, xi_ob, cov_ratio))\n",
    "\n",
    "    except RuntimeWarning:\n",
    "        print(sub)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Saliency Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_saliency_model_result_folder = '../Results/cross_validation/local_saliency_model_fold_0'\n",
    "local_saliency_model_samples = read_folder(local_saliency_model_result_folder, burnin)\n",
    "local_saliency_model_objects_dict = {}\n",
    "\n",
    "for sub in local_saliency_model_samples.keys():\n",
    "    try:\n",
    "        samples_xi_x, samples_xi_y = local_saliency_model_samples[sub]\n",
    "    except KeyError:\n",
    "        print(sub)\n",
    "        continue\n",
    "    \n",
    "    local_saliency_model_objects_dict[sub] = []\n",
    "    for i in range(num_samples):\n",
    "        chosen_ind = int(np.random.choice(np.linspace(0, len(samples_xi_x) - 1,len(samples_xi_x))))\n",
    "        xi_x = samples_xi_x[chosen_ind]\n",
    "        xi_y = samples_xi_y[chosen_ind]\n",
    "        \n",
    "        xi_ob = xi_object_local_saliency()\n",
    "        xi_ob.set_value(np.array([xi_x, xi_y]))\n",
    "        local_saliency_model_objects_dict[sub].append(local_saliency_model(test_saliencies, xi_ob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Choice Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_choice_model_results_folder = '../Results/cross_validation/fixed_choice_model_fold_0'\n",
    "fixed_choice_model_samples = read_folder(fixed_choice_model_results_folder, burnin)\n",
    "\n",
    "fixed_choice_model_objects_dict = {}\n",
    "\n",
    "for sub in fixed_choice_model_samples.keys():\n",
    "    try:\n",
    "        samples_rho, samples_epsilon_x, samples_epsilon_y, samples_xi_x, samples_xi_y = fixed_choice_model_samples[sub]\n",
    "    except ValueError:\n",
    "        print(sub)\n",
    "        continue\n",
    "\n",
    "    fixed_choice_model_objects_dict[sub] = []\n",
    "    for i in range(num_samples):\n",
    "        chosen_ind = int(np.random.choice(np.linspace(0, len(samples_rho) - 1,len(samples_rho))))\n",
    "        rho = samples_rho[chosen_ind]\n",
    "        eps_x = samples_epsilon_x[chosen_ind]\n",
    "        eps_y = samples_epsilon_y[chosen_ind]\n",
    "        xi_x = samples_xi_x[chosen_ind]\n",
    "        xi_y = samples_xi_y[chosen_ind]\n",
    "        \n",
    "        \n",
    "        rho_ob = rho_object()\n",
    "        rho_ob.set_value(rho)\n",
    "        eps_ob = epsilon_object()\n",
    "        eps_ob.set_value(np.array([eps_x, eps_y]))\n",
    "        xi_ob = xi_object()\n",
    "        xi_ob.set_value(np.array([xi_x, xi_y]))   \n",
    "\n",
    "        cov_ratio = 4\n",
    "        fixed_choice_model_objects_dict[sub].append(fixed_choice_model(test_saliencies, \n",
    "                                                                       rho_ob, eps_ob, \n",
    "                                                                       xi_ob, cov_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local choice model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_choice_model_results_folder = '../Results/cross_validation/local_choice_model_fold_0'\n",
    "local_choice_model_samples = read_folder(local_choice_model_results_folder, burnin)\n",
    "\n",
    "local_choice_model_objects_dict = {}\n",
    "\n",
    "for sub in local_choice_model_samples.keys():\n",
    "    try:\n",
    "        samples_s_0, samples_b, samples_epsilon_x, samples_epsilon_y, samples_xi_x, samples_xi_y = local_choice_model_samples[sub]\n",
    "    except ValueError:\n",
    "        print(sub)\n",
    "        continue\n",
    "    \n",
    "    local_choice_model_objects_dict[sub] = []\n",
    "    for i in range(num_samples):\n",
    "        chosen_ind = int(np.random.choice(np.linspace(0, len(samples_s_0) - 1,len(samples_s_0))))\n",
    "        s_0 = samples_s_0[chosen_ind]\n",
    "        b = samples_b[chosen_ind]\n",
    "        eps_x = samples_epsilon_x[chosen_ind]\n",
    "        eps_y = samples_epsilon_y[chosen_ind]\n",
    "        xi_x = samples_xi_x[chosen_ind]\n",
    "        xi_y = samples_xi_y[chosen_ind]\n",
    "        \n",
    "        s_0_ob = s_0_object()\n",
    "        s_0_ob.set_value(s_0)\n",
    "\n",
    "        b_ob = b_object()\n",
    "        b_ob.set_value(b)\n",
    "\n",
    "        eps_ob = epsilon_object()\n",
    "        eps_ob.set_value(np.array([eps_x, eps_y]))\n",
    "\n",
    "        xi_ob = xi_object()\n",
    "        xi_ob.set_value(np.array([xi_x, xi_y]))   \n",
    "\n",
    "        cov_ratio = 4\n",
    "        local_choice_model_objects_dict[sub].append(local_choice_model(test_saliencies, \n",
    "                                                                       s_0_ob, b_ob,\n",
    "                                                                       eps_ob, xi_ob, cov_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [full_model_objects_dict, local_saliency_model_objects_dict,\n",
    "              fixed_choice_model_objects_dict, local_choice_model_objects_dict]\n",
    "models_names = ['Full \\n model', 'Local \\n saliency \\n model', 'Fixed \\n choice \\n model', 'Local \\n choice \\n model']\n",
    "\n",
    "subjects = full_model_objects_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To process the data we put it in a dummy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the local saliency model as it is the simplest\n",
    "xi_dummy = xi_object_local_saliency()\n",
    "dummy_data_model = local_saliency_model(test_saliencies, xi_dummy)\n",
    "dummy_data_model.fixations = test_fixations\n",
    "dummy_data_model.set_fix_dist_2()\n",
    "dummy_data_model.set_saliencies_ts()\n",
    "dummy_data_model.fixs_degs = pix_to_degs(dummy_data_model.fixations)\n",
    "dummy_data_model.set_fix_dist_2_degs()\n",
    "dummy_data_model.set_angles_between_saccades_ts()\n",
    "dummy_data_model.set_angles_ts()\n",
    "\n",
    "data_fixs_dists_2_deg = dummy_data_model.fix_dists_2_degs\n",
    "data_fixs_dists_2 = dummy_data_model.fix_dists_2\n",
    "data_sals_ts = dummy_data_model.saliencies_ts\n",
    "data_dir_x = dummy_data_model.angles_x_ts\n",
    "data_dir_change = dummy_data_model.angles_between_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate NSS of the data for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/LocalGlobalAttentionModel/model.py:243: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(-arg))\n"
     ]
    }
   ],
   "source": [
    "# This will take a while if num_samples is big\n",
    "\n",
    "nss = np.empty((len(all_models), len(subjects), num_samples))\n",
    "\n",
    "for k, model in enumerate(all_models):\n",
    "    for s, sub in enumerate(subjects):\n",
    "        fixs_sub = [[test_fixations[i][s]] for i in range(len(test_fixations))]\n",
    "        sal_ts_sub = [[data_sals_ts[i][s]] for i in range(len(data_sals_ts))]\n",
    "        fix_dists_2_sub = [[data_fixs_dists_2[i][s]] for i in range(len(data_fixs_dists_2))]\n",
    "        for ind in range(num_samples):\n",
    "            res = model[sub][ind].calculate_likelihood_per_subject(fix_dists_2_sub, sal_ts_sub, fixs_sub, per_fixation=False, for_nss=True, saliencies=test_saliencies)\n",
    "            nss[k, s, ind] = np.array([res[im].mean() for im in range(len(res))]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_names)\n",
    "print(nss.mean(axis=(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = np.zeros((len(subjects), len(test_fixations)))\n",
    "for i, model in enumerate(all_models):\n",
    "    \n",
    "    for s, sub in enumerate(subjects):\n",
    "        if i == 0:\n",
    "            for k in range(len(test_fixations)):\n",
    "                time_steps[s, k] = test_fixations[k][s].shape[1]\n",
    "            time_steps = time_steps.astype(int)\n",
    "        \n",
    "        for j in range(num_samples):\n",
    "            gammas, fixs = model[sub][j].generate_dataset(time_steps[s], 1)\n",
    "            \n",
    "            model[sub][j].set_fixations(fixs)\n",
    "            model[sub][j].set_fix_dist_2()\n",
    "            model[sub][j].set_angles_ts()\n",
    "            model[sub][j].set_angles_between_saccades_ts()\n",
    "            model[sub][j].set_saliencies_ts()\n",
    "            model[sub][j].fixs_degs = pix_to_degs(model[sub][j].fixations)\n",
    "            model[sub][j].set_fix_dist_2_degs()\n",
    "            model[sub][j].set_angles_between_saccades_ts()\n",
    "            model[sub][j].set_angles_ts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pile together everything so we can plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fixs = np.sum([test_fixations[i][s].shape[1] for i in range(len(test_fixations)) for s in range(len(test_fixations[i]))])\n",
    "num_fixs_per_subject = np.array([np.sum([test_fixations[i][s].shape[1] for i in range(len(test_fixations))]) for s in range(len(subjects))])\n",
    "\n",
    "num_diffs = num_fixs - len(subjects) * len(test_fixations)\n",
    "flattend_fix_dist_2_deg = np.zeros((len(all_models), num_samples, num_diffs))\n",
    "gen_data_means = np.zeros((len(all_models), len(subjects), num_samples))\n",
    "gen_data_stds = np.zeros((len(all_models), len(subjects), num_samples))\n",
    "\n",
    "sacc_dir_means = np.zeros((len(all_models), len(subjects), num_samples))\n",
    "gen_data_stds = np.zeros((len(all_models), len(subjects), num_samples))\n",
    "\n",
    "for i, model in enumerate(all_models):\n",
    "    flat_dists_deg = []\n",
    "    flat_dists_pix = []\n",
    "    for l in range(num_samples):\n",
    "        all_subs = []\n",
    "        for s, sub in enumerate(subjects):\n",
    "            saccs_dir_sub = model[sub][l].angles_between_ts\n",
    "            dists_deg = [np.sqrt(model[sub][l].fix_dists_2_degs[im][0][-1, :]) for im in range(len(model[sub][l].fix_dists_2_degs))]            \n",
    "            sub_dat = np.concatenate(dists_deg)\n",
    "            all_subs.append(sub_dat)\n",
    "            gen_data_means[i][sub][l] = np.mean(sub_dat)\n",
    "            gen_data_stds[i][sub][l] = np.std(sub_dat)\n",
    "        flattend_fix_dist_2_deg[i][l] = np.concatenate(all_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saccade_lengths_data_deg = np.hstack([np.sqrt(data_fixs_dists_2_deg[i][s][-1,:]) for i in range(len(data_fixs_dists_2_deg)) for s in range(len(data_fixs_dists_2_deg[i]))]).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get densities of saccades amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.arange(-1, 25, 0.01)\n",
    "kdes_res = get_kdes_estimates(flattend_fix_dist_2_deg, positions)\n",
    "kde_data = gaussian_kde(saccade_lengths_data_deg)\n",
    "kde_res_data = kde_data(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdes_mean = kdes_res.mean(axis=1)\n",
    "kdes_percentiles = np.percentile(kdes_res, [2.5, 97.5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2,1, figsize=(12, 10), sharex=True)\n",
    "axarr[0].plot(positions, kde_res_data, label='Experimental Data', color='black')\n",
    "axarr[0].plot(positions, kdes_mean[0], label='Full Model', color='C1')\n",
    "axarr[0].plot(positions, kdes_mean[1], label='Local Saliency Model', color='C2')\n",
    "axarr[0].plot(positions, kdes_mean[2], label='Local Choice Model', color='C3')\n",
    "axarr[0].plot(positions, kdes_mean[3], label='Fixed Choice Model', color='C4')\n",
    "\n",
    "axarr[0].legend(fontsize=15)\n",
    "axarr[0].set_ylabel('Density', fontsize=30)\n",
    "axarr[0].tick_params(labelsize=20)\n",
    "\n",
    "axarr[1].plot(positions, kde_res_data, label='Experimental Data', color='black')\n",
    "axarr[1].plot(positions, kdes_mean[0], label='Full Model', color='C1')\n",
    "axarr[1].fill_between(positions, kdes_percentiles[0, 0], kdes_percentiles[1,0], color='peachpuff')\n",
    "axarr[1].plot(positions, kdes_mean[1], label='Local Saliency Model', color='C2')\n",
    "axarr[1].fill_between(positions, kdes_percentiles[0, 1], kdes_percentiles[1,1], color='#BFE2BF')\n",
    "axarr[1].legend(fontsize=15)\n",
    "axarr[1].set_xlabel('Saccade length [deg]', fontsize=30)\n",
    "axarr[1].set_ylabel('Density', fontsize=30)\n",
    "axarr[1].tick_params(labelsize=20)\n",
    "axarr[1].set_xlim((-1,20))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare mean and std of saccade amplitude per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_std_means = gen_data_stds.mean(axis=2)\n",
    "gen_data_means_means = gen_data_means.mean(axis=2)\n",
    "gen_data_means_errors = gen_data_std_means / np.sqrt(num_fixs_per_subject - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2, figsize=(10, 5))\n",
    "\n",
    "axarr[0].plot([3.8,8.5], [3.8, 8.5], linewidth=1)\n",
    "axarr[0].plot(data_means, gen_data_means_means[0], '+', markersize=10)\n",
    "axarr[0].set_xlabel('Subjects\\' mean \\n saccade length [deg]', fontsize=20)\n",
    "axarr[0].set_ylabel('Models\\' data mean \\n saccade length [deg]',  fontsize=20)\n",
    "axarr[0].set_xlim((3.8, 8.5))\n",
    "axarr[0].set_ylim((3.8, 8.5))\n",
    "\n",
    "axarr[1].plot([3., 5.2], [3., 5.2], linewidth=1)\n",
    "axarr[1].plot(data_stds, gen_data_std_means[0], '+', markersize=10)\n",
    "axarr[1].set_xlabel('Subjects\\'  \\n saccade length std [deg]', fontsize=20)\n",
    "axarr[1].set_ylabel('Models\\' data \\n saccade length std [deg]',  fontsize=20)\n",
    "axarr[1].set_xlim((3., 5.2))\n",
    "axarr[1].set_ylim((3., 5.2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saccade Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_angs_x = np.zeros((len(all_models), num_samples, num_diffs))\n",
    "all_angs_change = np.zeros((len(all_models), num_samples, num_diffs - (len(test_saliencies) * len(subjects))))\n",
    "for i, model in enumerate(all_models):\n",
    "    flat_angs_x = []\n",
    "    flat_angs_change = []\n",
    "    for l in range(num_samples):\n",
    "        all_subs_x = []\n",
    "        all_subs_change = []\n",
    "        for s, sub in enumerate(subjects):\n",
    "            saccs_dir_sub = model[sub][l].angles_x_ts\n",
    "            saccs_dir_change_sub = model[sub][l].angles_between_ts\n",
    "            sub_dir_x = np.concatenate([dat[0] for dat in saccs_dir_sub])\n",
    "            sub_dir_change = np.concatenate([dat[0] for dat in saccs_dir_change_sub])\n",
    "            all_subs_x.append(sub_dir_x)\n",
    "            all_subs_change.append(sub_dir_change)\n",
    "        all_angs_x[i][l] = np.concatenate(all_subs_x)\n",
    "        all_angs_change[i][l] = np.concatenate(all_subs_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_x_flat = np.hstack([data_dir_x[i][s] for i in range(len(data_dir_x)) for s in range(len(data_dir_x[i]))]).flatten()\n",
    "data_dir_change_flat = np.hstack([data_dir_change[i][s] for i in range(len(data_dir_change)) for s in range(len(data_dir_change[i]))]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.arange(-3.2, 3.2, 0.005)\n",
    "kdes_angs_x = get_kdes_estimates(all_angs_x, positions)\n",
    "kdes_angs_change = get_kdes_estimates(all_angs_change, positions)\n",
    "\n",
    "kde_data_angs_x = gaussian_kde(data_dir_x_flat)\n",
    "kde_data_angs_x = kde_data_angs_x(positions)\n",
    "\n",
    "kde_data_angs_change = gaussian_kde(data_dir_change_flat)\n",
    "kde_data_angs_change = kde_data_angs_change(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdes_mean_angs_x = kdes_angs_x.mean(axis=1)\n",
    "kdes_mean_angs_change = kdes_angs_change.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2, figsize=(12, 4))\n",
    "axarr[0].plot(positions, kde_data_angs_x, label='Experimental Data', color='black')\n",
    "axarr[0].plot(positions, kdes_mean_angs_x[0], label='Full Model', color='C1')\n",
    "axarr[0].plot(positions, kdes_mean_angs_x[1], label='Local Saliency Model', color='C2')\n",
    "axarr[0].plot(positions, kdes_mean_angs_x[2], label='Local Choice Model', color='C3')\n",
    "axarr[0].plot(positions, kdes_mean_angs_x[3], label='Fixed Choice Model', color='C4')\n",
    "\n",
    "axarr[0].legend(fontsize=10)\n",
    "axarr[0].set_ylabel('Density', fontsize=20)\n",
    "axarr[0].set_xlabel('saccade direction', fontsize=20)\n",
    "axarr[0].tick_params(labelsize=10)\n",
    "\n",
    "axarr[1].plot(positions, kde_data_angs_change, label='Experimental Data', color='black')\n",
    "axarr[1].plot(positions, kdes_mean_angs_change[0], label='Full Model', color='C1')\n",
    "axarr[1].plot(positions, kdes_mean_angs_change[1], label='Local Saliency Model', color='C2')\n",
    "axarr[1].plot(positions, kdes_mean_angs_change[2], label='Local Choice Model', color='C3')\n",
    "axarr[1].plot(positions, kdes_mean_angs_change[3], label='Fixed Choice Model', color='C4')\n",
    "\n",
    "axarr[1].set_ylabel('Density', fontsize=20)\n",
    "axarr[1].set_xlabel('saccade change', fontsize=20)\n",
    "axarr[1].tick_params(labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
